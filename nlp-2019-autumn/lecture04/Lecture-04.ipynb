{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 04 Deep Learning and Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nueral Network and Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract netural network graph node.\n",
    "\n",
    "class Node(object):\n",
    "    \"\"\"\n",
    "    Node\n",
    "    \"\"\"\n",
    "    def __init__(self, inputs=[]):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "\n",
    "        for n in self.inputs:\n",
    "            n.outputs.append(self) # set 'self' node as inbound_node's outbound_nodes\n",
    "\n",
    "        self.value = None\n",
    "\n",
    "        # keys are the inputs to this node and their values are partials of this node\n",
    "        # with respect to that input.\n",
    "        # \\partial{node}{input_i}\n",
    "        self.gradients = {}\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "        Compute the output value based on 'inbound_nodes' and store the results\n",
    "        in self.value\n",
    "        \"\"\"\n",
    "        raise  NotImplemented()\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Back propagation.\n",
    "        \"\"\"\n",
    "        raise NotImplemented()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input(Node):\n",
    "    \"\"\"\n",
    "    Input Node.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        Node.__init__(self)\n",
    "\n",
    "    def forward(self, value=None):\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "\n",
    "        Only input node is the node where the value may be passed as an argument to forward().\n",
    "        All other node implementation should get value of the previous node from self.inbound[0].value\n",
    "        \"\"\"\n",
    "        if value is not None:\n",
    "            self.value = value\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Back propagation.\n",
    "        \"\"\"\n",
    "        self.gradients = {self: 0}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self] = grad_cost * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(Node):\n",
    "    \"\"\"\n",
    "    Add operation.\n",
    "    \"\"\"\n",
    "    def __init__(self, *nodes):\n",
    "        Node.__init__(self, nodes)\n",
    "\n",
    "    def forward(self):\n",
    "        self.value = sum(map(lambda n: n.value, self.inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = w*x + b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Node):\n",
    "    \"\"\"\n",
    "    Linear Op.\n",
    "    \"\"\"\n",
    "    def __init__(self, nodes, weights, bias):\n",
    "        Node.__init__(self, [nodes, weights, bias])\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "        y = w*x + b\n",
    "        \"\"\"\n",
    "        inputs = self.inputs[0].value\n",
    "        weights = self.inputs[1].value\n",
    "        bias = self.inputs[2].value\n",
    "\n",
    "        self.value = np.dot(inputs, weights) + bias\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Backword propagation.\n",
    "        \"\"\"\n",
    "        # initialize a partial for each inbound_nodes.\n",
    "        self.gradients = { n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "\n",
    "            self.gradients[self.inputs[0]] = np.dot(grad_cost, self.inputs[1].value.T)\n",
    "            self.gradients[self.inputs[1]] = np.dot(self.inputs[0].value.T, grad_cost)\n",
    "            self.gradients[self.inputs[2]] = np.sum(grad_cost, axis=0, keepdims=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sigma(x) = \\frac{1}{1 + e^{-x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_sigmoid(x):\n",
    "    \"\"\"\n",
    "    sigmoid operation.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sigma'(x) = \\sigma * (1 - \\sigma)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_sigmoid_derivative(x):\n",
    "    \"\"\"\n",
    "    sigmoid derivative.\n",
    "    \"\"\"\n",
    "    return op_sigmoid(x) * (1 - op_sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Node):\n",
    "    \"\"\"\n",
    "    Sigmoid Op.\n",
    "    \"\"\"\n",
    "    def __init__(self, node):\n",
    "        Node.__init__(self, [node])\n",
    "\n",
    "    def forward(self,):\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "        \"\"\"\n",
    "        self.x = self.inputs[0].value\n",
    "        self.value = op_sigmoid(self.x)\n",
    "\n",
    "    def backward(self,):\n",
    "        \"\"\"\n",
    "        Back propagation.\n",
    "        \"\"\"\n",
    "        self.gradients = { n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self.inputs[0]] = grad_cost * op_sigmoid_derivative(self.x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L(y, \\hat{y}) = \\frac{1}{N}\\sum{(y - \\hat{y})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial L}{\\partial{y}} = \\frac{2}{N} \\sum{(y - \\hat{y})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial L}{\\partial{\\hat{y}}} = -\\frac{2}{N} \\sum{(y - \\hat{y})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Node):\n",
    "    \"\"\"\n",
    "    Mean Square Error.\n",
    "    \"\"\"\n",
    "    def __init__(self, y, y_hat):\n",
    "        Node.__init__(self, [y, y_hat])\n",
    "\n",
    "    def forward(self):\n",
    "        y = self.inputs[0].value.reshape(-1, 1)\n",
    "        y_hat = self.inputs[1].value.reshape(-1, 1)\n",
    "        assert y.shape == y_hat.shape\n",
    "\n",
    "        self.m = self.inputs[0].value.shape[0]\n",
    "        self.diff = y - y_hat\n",
    "\n",
    "        self.value = np.mean(self.diff ** 2)\n",
    "\n",
    "    def backward(self):\n",
    "        self.gradients[self.inputs[0]] = (2 / self.m) * self.diff\n",
    "        self.gradients[self.inputs[1]] = (-2 / self.m) * self.diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(output_node, graph):\n",
    "    \"\"\"\n",
    "    Execute all the forward method of sorted nodes.\n",
    "    \"\"\"\n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "\n",
    "    for n in graph[::-1]:\n",
    "        n.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort generic nodes in topological order using Kahn's Algorithm.\n",
    "    `feed_dict`: A dictionary where the key is a `Input` node and the value is the respective value feed to that node.\n",
    "    Returns a list of sorted nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outputs:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "            ## if n is Input Node, set n'value as \n",
    "            ## feed_dict[n]\n",
    "            ## else, n's value is caculate as its\n",
    "            ## inbounds\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outputs:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_update(trainables, learning_rate=1e-3):\n",
    "    \"\"\"\n",
    "    Stochastic Grandient Descent.\n",
    "    \"\"\"\n",
    "    for t in trainables:\n",
    "        t.value += -1 * learning_rate * t.gradients[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle, resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_dataset = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_dataset.data.shape, boston_dataset.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle, resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 433.538\n",
      "Epoch: 100, Loss: 15.510\n",
      "Epoch: 200, Loss: 10.901\n",
      "Epoch: 300, Loss: 9.171\n",
      "Epoch: 400, Loss: 9.561\n",
      "Epoch: 500, Loss: 10.405\n",
      "Epoch: 600, Loss: 8.227\n",
      "Epoch: 700, Loss: 8.600\n",
      "Epoch: 800, Loss: 8.637\n",
      "Epoch: 900, Loss: 6.687\n",
      "Epoch: 1000, Loss: 8.613\n",
      "Epoch: 1100, Loss: 8.066\n",
      "Epoch: 1200, Loss: 6.871\n",
      "Epoch: 1300, Loss: 6.408\n",
      "Epoch: 1400, Loss: 6.765\n",
      "Epoch: 1500, Loss: 7.439\n",
      "Epoch: 1600, Loss: 6.844\n",
      "Epoch: 1700, Loss: 6.010\n",
      "Epoch: 1800, Loss: 6.684\n",
      "Epoch: 1900, Loss: 6.303\n"
     ]
    }
   ],
   "source": [
    "dataset = load_boston()\n",
    "\n",
    "X_ = dataset['data']\n",
    "Y_ = dataset['target']\n",
    "\n",
    "# normalize data\n",
    "X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0)\n",
    "\n",
    "n_features = X_.shape[1] # feature number\n",
    "n_hidden = 10  # hidden layer node number\n",
    "\n",
    "\n",
    "# Initialize W1, b1, W2, b2 paramerters\n",
    "W1_ = np.random.randn(n_features, n_hidden)\n",
    "b1_ = np.zeros(n_hidden)\n",
    "W2_ = np.random.randn(n_hidden, 1)\n",
    "b2_ = np.zeros(1)\n",
    "\n",
    "# Neural Network\n",
    "X, Y = Input(), Input()\n",
    "W1, b1 = Input(), Input()\n",
    "W2, b2 = Input(), Input()\n",
    "\n",
    "l1 = Linear(X, W1, b1)\n",
    "s1 = Sigmoid(l1)\n",
    "l2 = Linear(s1, W2, b2)\n",
    "cost = MSE(Y, l2)\n",
    "\n",
    "feed_dict = {\n",
    "    X: X_,\n",
    "    Y: Y_,\n",
    "    W1: W1_,\n",
    "    b1: b1_,\n",
    "    W2: W2_,\n",
    "    b2: b2_\n",
    "}\n",
    "\n",
    "epochs = 2000\n",
    "\n",
    "m = X_.shape[0]\n",
    "batch_size = 16\n",
    "steps_per_epoch = m // batch_size\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "trainables = [W1, b1, W2, b2]\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    for j in range(steps_per_epoch):\n",
    "        X_batch, Y_batch = resample(X_, Y_, n_samples=batch_size)\n",
    "        \n",
    "        X.value = X_batch\n",
    "        Y.value = Y_batch\n",
    "\n",
    "        # forward and backward\n",
    "        forward_and_backward(None, graph)\n",
    "\n",
    "        # sgd\n",
    "        sgd_update(trainables)\n",
    "\n",
    "        loss += graph[-1].value\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(\"Epoch: {}, Loss: {:.3f}\".format(i, loss/steps_per_epoch))\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10aaff150>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/hotbaby/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/hotbaby/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/hotbaby/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/hotbaby/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/hotbaby/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/hotbaby/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intput:`13` -> Layer1:`40` -> Layer2:`10` -> output: `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=40, activation='sigmoid', input_dim=13))\n",
    "model.add(Dense(units=10, activation='sigmoid', input_dim=40))\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='sgd', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_, Y_, epochs=1000, batch_size=32, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
